# Метчинг товаров

Дано два множества объектов: множество A и множество B. Каждый объект в каждом множестве описывается определенными признаками. Цель состоит в том, чтобы для каждого объекта из множества A найти один или несколько объектов из множества B, которые схожи с ним по определенной метрике. Важно отметить, что множества A и B могут быть как различными, так и одинаковыми, и в процессе поиска соответствий может возникнуть ситуация, когда ни один объект из B не будет соответствовать объекту из A.

## Задача:

- Разработать алгоритм, который для всех товаров из validation.csv предложит несколько вариантов наиболее похожих товаров из base;
- Оценить качество алгоритма по метрике accuracy@5.

## План по выполнению проекта
1. Загрузка данных
2. Предобработка и исследовательский анализ данных
3. Подготовка выборок для обучения
4. Разработка ранжирующих моделей
5. Анализ моделей
6. Отчет по исследованию

## Исходные данные

- base.csv - анонимизированный набор товаров. Каждый товар представлен как уникальный id (0-base, 1-base, 2-base) и вектор признаков размерностью 72.

- train.csv - обучающий датасет. Каждая строчка - один товар, для которого известен уникальный id (0-query, 1-query, …), вектор признаков и id товара из base.csv, который максимально похож на него (по мнению экспертов).

- validation.csv - датасет с товарами (уникальный id и вектор признаков), для которых надо найти наиболее близкие товары из base.csv.

- validation_answer.csv - правильные ответы к предыдущему файлу.

Для поиска ближайших соседей использована библиотека FAISS.

Для решения задачи созданы три выборки:
1. Первая выборка содержит исходные датасеты без изменений.
2. Вторая выборка включает только признаки с нормальным распределением, исключая определенные столбцы.
3. Третья выборка содержит признаки из первых двух выборок, преобразованные с использованием метода главных компонент (PCA).

Для каждой выборки производится перебор размера кластера и количества ближайших кластеров.

По итогу, лучше всего показали себя модели из второй выборки и модели из той же выборки, но проведенные через PCA() со снижением дисперсии на 20%.
Наиболее высокий показатель accuracy = 70.8% с оптимальным количеством времени обучения - достигнут для второй выборки с n_cells = 50 и n_nprobe = 15.
